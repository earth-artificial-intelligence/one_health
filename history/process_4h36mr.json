[{
  "history_id" : "AvFA9EiGTe7Q",
  "history_input" : "import os\nimport pandas as pd\n\n# Define the directory where datasets are stored\nTARGET_DIRECTORY = \"/media/volume1\"\n\n# Define file paths\nCLEANED_FINAL_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"cleaned_final_merged_dataset.csv\")\nBIRDS_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"hpai-wild-birds-2022.csv\")\nOUTPUT_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"final_merged_with_birds.csv\")\n\ndef load_dataset(file_path):\n    \"\"\"\n    Loads the dataset from the given file path.\n\n    Args:\n        file_path (str): Path to the dataset.\n\n    Returns:\n        pd.DataFrame: Loaded pandas DataFrame.\n    \"\"\"\n    if not os.path.exists(file_path):\n        print(f\"Error: File '{file_path}' not found.\")\n        return None\n\n    try:\n        df = pd.read_csv(file_path)\n        print(f\"Dataset loaded successfully from {file_path}\")\n        return df\n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        return None\n\ndef merge_datasets(aqi_cancer_df, birds_df):\n    \"\"\"\n    Merges the AQI-Cancer dataset with the Birds dataset based on 'County'.\n    Retains the 'State' column from AQI-Cancer data.\n    Removes duplicate 'County' and 'State' columns from the Birds dataset.\n\n    Args:\n        aqi_cancer_df (pd.DataFrame): The cleaned AQI-Cancer dataset.\n        birds_df (pd.DataFrame): The birds dataset.\n\n    Returns:\n        pd.DataFrame: Merged dataset.\n    \"\"\"\n    try:\n        # Keep a copy of the State column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            state_map = aqi_cancer_df.set_index(\"County\")[\"State\"].to_dict()\n        \n        # Merge datasets on 'County', keeping all columns (fill missing values with NaN)\n        merged_df = aqi_cancer_df.merge(birds_df, on=\"County\", how=\"left\")\n\n        # Restore the 'State' column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            merged_df[\"State\"] = merged_df[\"County\"].map(state_map)\n\n        # Drop the duplicate 'County' and 'State' columns from the Birds dataset\n        columns_to_drop = [col for col in [\"State_x\", \"State_y\"] if col in merged_df.columns]\n        merged_df.drop(columns=columns_to_drop, errors=\"ignore\", inplace=True)\n\n        print(\"Datasets merged successfully.\")\n        return merged_df\n    except Exception as e:\n        print(f\"Error during merging: {e}\")\n        return None\n\ndef reorder_columns(df):\n    \"\"\"\n    Moves the 'State' column to the first position.\n\n    Args:\n        df (pd.DataFrame): The dataset to reorder.\n\n    Returns:\n        pd.DataFrame: Dataset with 'State' as the first column.\n    \"\"\"\n    if \"State\" in df.columns:\n        column_order = [\"State\"] + [col for col in df.columns if col != \"State\"]\n        df = df[column_order]\n        print(\"Moved 'State' column to the first position.\")\n    else:\n        print(\"Warning: 'State' column not found in dataset.\")\n    \n    return df\n\ndef save_dataset(df, file_path):\n    \"\"\"\n    Saves the merged dataset to the specified file path.\n\n    Args:\n        df (pd.DataFrame): The merged dataset.\n        file_path (str): Path to save the dataset.\n    \"\"\"\n    try:\n        df.to_csv(file_path, index=False)\n        print(f\"Merged dataset saved successfully as '{file_path}'.\")\n    except Exception as e:\n        print(f\"Error saving dataset: {e}\")\n\ndef print_dataset_info(df):\n    \"\"\"\n    Prints the dataset's column names, first 10 rows, and total number of rows and columns.\n\n    Args:\n        df (pd.DataFrame): The dataset to print.\n    \"\"\"\n    num_rows, num_columns = df.shape\n    print(f\"\\nTotal Rows: {num_rows}, Total Columns: {num_columns}\")\n\n    print(\"\\nAll Columns in Merged Dataset:\")\n    print(list(df.columns))\n\n    print(\"\\nFirst 10 Rows of Merged Dataset:\")\n    print(df.head(10))\n\ndef main():\n    \"\"\"\n    Main function to load, merge, reorder, save, and print dataset information.\n    \"\"\"\n    aqi_cancer_df = load_dataset(CLEANED_FINAL_DATA_PATH)\n    birds_df = load_dataset(BIRDS_DATA_PATH)\n\n    if aqi_cancer_df is not None and birds_df is not None:\n        merged_df = merge_datasets(aqi_cancer_df, birds_df)\n        if merged_df is not None:\n            merged_df = reorder_columns(merged_df)  # Move 'State' column to first position\n            save_dataset(merged_df, OUTPUT_FILE_PATH)\n            print_dataset_info(merged_df)  # Print dataset info after merging\n\nif __name__ == \"__main__\":\n    main()\n",
  "history_output" : "Dataset loaded successfully from /media/volume1/cleaned_final_merged_dataset.csv\nDataset loaded successfully from /media/volume1/hpai-wild-birds-2022.csv\nDatasets merged successfully.\nMoved 'State' column to the first position.\nMerged dataset saved successfully as '/media/volume1/final_merged_with_birds.csv'.\nTotal Rows: 22242, Total Columns: 36\nAll Columns in Merged Dataset:\n['State', 'County', 'Year', 'Days with AQI', 'Good Days', 'Moderate Days', 'Unhealthy for Sensitive Groups Days', 'Unhealthy Days', 'Very Unhealthy Days', 'Hazardous Days', 'Max AQI', '90th Percentile AQI', 'Median AQI', 'Days CO', 'Days NO2', 'Days Ozone', 'Days PM2.5', 'Days PM10', '2023 Rural-Urban Continuum Codes([rural urban note])', 'Age-Adjusted Incidence Rate([rate note]) - cases per 100,000', 'Lower 95% Confidence Interval', 'Upper 95% Confidence Interval', 'Average Annual Count', 'Recent Trend', 'Recent 5-Year Trend ([trend note]) in Incidence Rates', 'Lower 95% Confidence Interval.1', 'Upper 95% Confidence Interval.1', 'Region', 'Zone', 'Collection Date', 'Date Detected', 'HPAI Strain', 'Bird Species', 'WOAH Classification', 'Sampling Method', 'Submitting Agency']\nFirst 10 Rows of Merged Dataset:\n     State   County  ...      Sampling Method             Submitting Agency\n0  Alabama  Baldwin  ...                  NaN                           NaN\n1  Alabama     Clay  ...  Morbidity/Mortality  MO Dept of Conservation/USGS\n2  Alabama     Clay  ...  Morbidity/Mortality                  KS DWP/SCWDS\n3  Alabama     Clay  ...  Morbidity/Mortality                       FL FWCC\n4  Alabama     Clay  ...  Morbidity/Mortality                       FL FWCC\n5  Alabama     Clay  ...  Morbidity/Mortality                       FL FWCC\n6  Alabama     Clay  ...  Morbidity/Mortality                       FL FWCC\n7  Alabama     Clay  ...  Morbidity/Mortality                          NWDP\n8  Alabama     Clay  ...       Hunter Harvest                          NWDP\n9  Alabama     Clay  ...       Hunter Harvest                          NWDP\n[10 rows x 36 columns]\n",
  "history_begin_time" : 1742475773630,
  "history_end_time" : 1742475774474,
  "history_notes" : null,
  "history_process" : "4h36mr",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "z6EjNkfwWKzu",
  "history_input" : "import os\nimport pandas as pd\n\n# Define the directory where datasets are stored\nTARGET_DIRECTORY = \"/media/volume1\"\n\n# Define file paths\nCLEANED_FINAL_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"cleaned_final_merged_dataset.csv\")\nBIRDS_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"hpai-wild-birds-2022.csv\")\nOUTPUT_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"final_merged_with_birds.csv\")\n\ndef load_dataset(file_path):\n    \"\"\"\n    Loads the dataset from the given file path.\n\n    Args:\n        file_path (str): Path to the dataset.\n\n    Returns:\n        pd.DataFrame: Loaded pandas DataFrame.\n    \"\"\"\n    if not os.path.exists(file_path):\n        print(f\"Error: File '{file_path}' not found.\")\n        return None\n\n    try:\n        df = pd.read_csv(file_path)\n        print(f\"Dataset loaded successfully from {file_path}\")\n        return df\n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        return None\n\ndef merge_datasets(aqi_cancer_df, birds_df):\n    \"\"\"\n    Merges the AQI-Cancer dataset with the Birds dataset based on 'County'.\n    Retains the 'State' column from AQI-Cancer data.\n    Removes duplicate 'County' and 'State' columns from the Birds dataset.\n\n    Args:\n        aqi_cancer_df (pd.DataFrame): The cleaned AQI-Cancer dataset.\n        birds_df (pd.DataFrame): The birds dataset.\n\n    Returns:\n        pd.DataFrame: Merged dataset.\n    \"\"\"\n    try:\n        # Keep a copy of the State column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            state_map = aqi_cancer_df.set_index(\"County\")[\"State\"].to_dict()\n        \n        # Merge datasets on 'County', keeping all columns (fill missing values with NaN)\n        merged_df = aqi_cancer_df.merge(birds_df, on=\"County\", how=\"left\")\n\n        # Restore the 'State' column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            merged_df[\"State\"] = merged_df[\"County\"].map(state_map)\n\n        # Drop the duplicate 'County' and 'State' columns from the Birds dataset\n        columns_to_drop = [col for col in [\"State_x\", \"State_y\"] if col in merged_df.columns]\n        merged_df.drop(columns=columns_to_drop, errors=\"ignore\", inplace=True)\n\n        print(\"Datasets merged successfully.\")\n        return merged_df\n    except Exception as e:\n        print(f\"Error during merging: {e}\")\n        return None\n\ndef save_dataset(df, file_path):\n    \"\"\"\n    Saves the merged dataset to the specified file path.\n\n    Args:\n        df (pd.DataFrame): The merged dataset.\n        file_path (str): Path to save the dataset.\n    \"\"\"\n    try:\n        df.to_csv(file_path, index=False)\n        print(f\"Merged dataset saved successfully as '{file_path}'.\")\n    except Exception as e:\n        print(f\"Error saving dataset: {e}\")\n\ndef print_dataset_info(df):\n    \"\"\"\n    Prints the dataset's column names, first 10 rows, and total number of rows and columns.\n\n    Args:\n        df (pd.DataFrame): The dataset to print.\n    \"\"\"\n    num_rows, num_columns = df.shape\n    print(f\"\\nTotal Rows: {num_rows}, Total Columns: {num_columns}\")\n\n    print(\"\\nAll Columns in Merged Dataset:\")\n    print(list(df.columns))\n\n    print(\"\\nFirst 10 Rows of Merged Dataset:\")\n    print(df.head(10))\n\ndef main():\n    \"\"\"\n    Main function to load, merge, save, and print dataset information.\n    \"\"\"\n    aqi_cancer_df = load_dataset(CLEANED_FINAL_DATA_PATH)\n    birds_df = load_dataset(BIRDS_DATA_PATH)\n\n    if aqi_cancer_df is not None and birds_df is not None:\n        merged_df = merge_datasets(aqi_cancer_df, birds_df)\n        if merged_df is not None:\n            save_dataset(merged_df, OUTPUT_FILE_PATH)\n            print_dataset_info(merged_df)  # Print dataset info after merging\n\nif __name__ == \"__main__\":\n    main()\n",
  "history_output" : "Dataset loaded successfully from /media/volume1/cleaned_final_merged_dataset.csv\nDataset loaded successfully from /media/volume1/hpai-wild-birds-2022.csv\nDatasets merged successfully.\nMerged dataset saved successfully as '/media/volume1/final_merged_with_birds.csv'.\nTotal Rows: 22242, Total Columns: 36\nAll Columns in Merged Dataset:\n['County', 'Year', 'Days with AQI', 'Good Days', 'Moderate Days', 'Unhealthy for Sensitive Groups Days', 'Unhealthy Days', 'Very Unhealthy Days', 'Hazardous Days', 'Max AQI', '90th Percentile AQI', 'Median AQI', 'Days CO', 'Days NO2', 'Days Ozone', 'Days PM2.5', 'Days PM10', '2023 Rural-Urban Continuum Codes([rural urban note])', 'Age-Adjusted Incidence Rate([rate note]) - cases per 100,000', 'Lower 95% Confidence Interval', 'Upper 95% Confidence Interval', 'Average Annual Count', 'Recent Trend', 'Recent 5-Year Trend ([trend note]) in Incidence Rates', 'Lower 95% Confidence Interval.1', 'Upper 95% Confidence Interval.1', 'Region', 'Zone', 'Collection Date', 'Date Detected', 'HPAI Strain', 'Bird Species', 'WOAH Classification', 'Sampling Method', 'Submitting Agency', 'State']\nFirst 10 Rows of Merged Dataset:\n    County  Year  ...             Submitting Agency    State\n0  Baldwin  2017  ...                           NaN  Alabama\n1     Clay  2017  ...  MO Dept of Conservation/USGS  Alabama\n2     Clay  2017  ...                  KS DWP/SCWDS  Alabama\n3     Clay  2017  ...                       FL FWCC  Alabama\n4     Clay  2017  ...                       FL FWCC  Alabama\n5     Clay  2017  ...                       FL FWCC  Alabama\n6     Clay  2017  ...                       FL FWCC  Alabama\n7     Clay  2017  ...                          NWDP  Alabama\n8     Clay  2017  ...                          NWDP  Alabama\n9     Clay  2017  ...                          NWDP  Alabama\n[10 rows x 36 columns]\n",
  "history_begin_time" : 1742475506062,
  "history_end_time" : 1742475507024,
  "history_notes" : null,
  "history_process" : "4h36mr",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rJZRcW7FnPoa",
  "history_input" : "import os\nimport pandas as pd\n\n# Define the directory where datasets are stored\nTARGET_DIRECTORY = \"/media/volume1\"\n\n# Define file paths\nCLEANED_FINAL_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"cleaned_final_merged_dataset.csv\")\nBIRDS_DATA_PATH = os.path.join(TARGET_DIRECTORY, \"hpai-wild-birds-2022.csv\")\nOUTPUT_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"final_merged_with_birds.csv\")\n\ndef load_dataset(file_path):\n    \"\"\"\n    Loads the dataset from the given file path.\n\n    Args:\n        file_path (str): Path to the dataset.\n\n    Returns:\n        pd.DataFrame: Loaded pandas DataFrame.\n    \"\"\"\n    if not os.path.exists(file_path):\n        print(f\"Error: File '{file_path}' not found.\")\n        return None\n\n    try:\n        df = pd.read_csv(file_path)\n        print(f\"Dataset loaded successfully from {file_path}\")\n        return df\n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        return None\n\ndef merge_datasets(aqi_cancer_df, birds_df):\n    \"\"\"\n    Merges the AQI-Cancer dataset with the Birds dataset based on 'County'.\n    Retains the 'State' column from AQI-Cancer data.\n    Removes duplicate 'County' and 'State' columns from the Birds dataset.\n\n    Args:\n        aqi_cancer_df (pd.DataFrame): The cleaned AQI-Cancer dataset.\n        birds_df (pd.DataFrame): The birds dataset.\n\n    Returns:\n        pd.DataFrame: Merged dataset.\n    \"\"\"\n    try:\n        # Keep a copy of the State column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            state_map = aqi_cancer_df.set_index(\"County\")[\"State\"].to_dict()\n        \n        # Merge datasets on 'County', keeping all columns (fill missing values with NaN)\n        merged_df = aqi_cancer_df.merge(birds_df, on=\"County\", how=\"left\")\n\n        # Restore the 'State' column from AQI-Cancer dataset\n        if \"State\" in aqi_cancer_df.columns:\n            merged_df[\"State\"] = merged_df[\"County\"].map(state_map)\n\n        # Drop the duplicate 'County' and 'State' columns from the Birds dataset\n        columns_to_drop = [col for col in [\"State_x\", \"State_y\"] if col in merged_df.columns]\n        merged_df.drop(columns=columns_to_drop, errors=\"ignore\", inplace=True)\n\n        print(\"Datasets merged successfully.\")\n        return merged_df\n    except Exception as e:\n        print(f\"Error during merging: {e}\")\n        return None\n\ndef save_dataset(df, file_path):\n    \"\"\"\n    Saves the merged dataset to the specified file path.\n\n    Args:\n        df (pd.DataFrame): The merged dataset.\n        file_path (str): Path to save the dataset.\n    \"\"\"\n    try:\n        df.to_csv(file_path, index=False)\n        print(f\"Merged dataset saved successfully as '{file_path}'.\")\n    except Exception as e:\n        print(f\"Error saving dataset: {e}\")\n\ndef print_dataset_info(df):\n    \"\"\"\n    Prints the dataset's column names, first 10 rows, and total number of rows and columns.\n\n    Args:\n        df (pd.DataFrame): The dataset to print.\n    \"\"\"\n    num_rows, num_columns = df.shape\n    print(f\"\\nTotal Rows: {num_rows}, Total Columns: {num_columns}\")\n\n    print(\"\\nAll Columns in Merged Dataset:\")\n    print(list(df.columns))\n\n    print(\"\\nFirst 10 Rows of Merged Dataset:\")\n    print(df.head(10))\n\ndef main():\n    \"\"\"\n    Main function to load, merge, save, and print dataset information.\n    \"\"\"\n    aqi_cancer_df = load_dataset(CLEANED_FINAL_DATA_PATH)\n    birds_df = load_dataset(BIRDS_DATA_PATH)\n\n    if aqi_cancer_df is not None and birds_df is not None:\n        merged_df = merge_datasets(aqi_cancer_df, birds_df)\n        if merged_df is not None:\n            save_dataset(merged_df, OUTPUT_FILE_PATH)\n            print_dataset_info(merged_df)  # Print dataset info after merging\n\nif __name__ == \"__main__\":\n    main()\n",
  "history_output" : "Dataset loaded successfully from /media/volume1/cleaned_final_merged_dataset.csv\nDataset loaded successfully from /media/volume1/hpai-wild-birds-2022.csv\nDatasets merged successfully.\nMerged dataset saved successfully as '/media/volume1/final_merged_with_birds.csv'.\nTotal Rows: 22242, Total Columns: 36\nAll Columns in Merged Dataset:\n['County', 'Year', 'Days with AQI', 'Good Days', 'Moderate Days', 'Unhealthy for Sensitive Groups Days', 'Unhealthy Days', 'Very Unhealthy Days', 'Hazardous Days', 'Max AQI', '90th Percentile AQI', 'Median AQI', 'Days CO', 'Days NO2', 'Days Ozone', 'Days PM2.5', 'Days PM10', '2023 Rural-Urban Continuum Codes([rural urban note])', 'Age-Adjusted Incidence Rate([rate note]) - cases per 100,000', 'Lower 95% Confidence Interval', 'Upper 95% Confidence Interval', 'Average Annual Count', 'Recent Trend', 'Recent 5-Year Trend ([trend note]) in Incidence Rates', 'Lower 95% Confidence Interval.1', 'Upper 95% Confidence Interval.1', 'Region', 'Zone', 'Collection Date', 'Date Detected', 'HPAI Strain', 'Bird Species', 'WOAH Classification', 'Sampling Method', 'Submitting Agency', 'State']\nFirst 10 Rows of Merged Dataset:\n    County  Year  ...             Submitting Agency    State\n0  Baldwin  2017  ...                           NaN  Alabama\n1     Clay  2017  ...  MO Dept of Conservation/USGS  Alabama\n2     Clay  2017  ...                  KS DWP/SCWDS  Alabama\n3     Clay  2017  ...                       FL FWCC  Alabama\n4     Clay  2017  ...                       FL FWCC  Alabama\n5     Clay  2017  ...                       FL FWCC  Alabama\n6     Clay  2017  ...                       FL FWCC  Alabama\n7     Clay  2017  ...                          NWDP  Alabama\n8     Clay  2017  ...                          NWDP  Alabama\n9     Clay  2017  ...                          NWDP  Alabama\n[10 rows x 36 columns]\n",
  "history_begin_time" : 1742475476904,
  "history_end_time" : 1742475477838,
  "history_notes" : null,
  "history_process" : "4h36mr",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fpgRhnPuanZF",
  "history_input" : "import os\nimport pandas as pd\n\n# Define file paths\nTARGET_DIRECTORY = \"/media/volume1\"\nBIRDS_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"hpai-wild-birds-2022.csv\")  # Filtered birds data for 2022\nCLEANED_FINAL_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"cleaned_final_merged_dataset.csv\")\nMERGED_FILE_PATH = os.path.join(TARGET_DIRECTORY, \"final_merged_with_birds.csv\")\n\ndef load_dataset(file_path):\n    \"\"\"\n    Loads a dataset from the specified file path.\n    \n    Args:\n        file_path (str): Path to the dataset.\n    \n    Returns:\n        pd.DataFrame: Loaded pandas DataFrame.\n    \"\"\"\n    if not os.path.exists(file_path):\n        print(f\"Error: File '{file_path}' not found.\")\n        return None\n\n    try:\n        df = pd.read_csv(file_path)\n        print(f\"Dataset loaded successfully from {file_path}\")\n        return df\n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        return None\n\ndef merge_datasets(cleaned_df, birds_df):\n    \"\"\"\n    Merges the cleaned dataset with the birds dataset based on 'County'.\n    \n    Args:\n        cleaned_df (pd.DataFrame): The cleaned final dataset.\n        birds_df (pd.DataFrame): The birds dataset.\n\n    Returns:\n        pd.DataFrame: Merged dataset.\n    \"\"\"\n    try:\n        # Merge on County, keeping all data\n        merged_df = cleaned_df.merge(birds_df, on=\"County\", how=\"left\")\n\n        # Drop duplicate 'State' and 'County' columns from birds dataset\n        merged_df.drop(columns=[\"State_x\", \"State_y\"], errors=\"ignore\", inplace=True)\n\n        print(\"Datasets merged successfully.\")\n        return merged_df\n    except Exception as e:\n        print(f\"Error during merging: {e}\")\n        return None\n\ndef save_merged_dataset(df, file_path):\n    \"\"\"\n    Saves the merged dataset to the specified file path.\n\n    Args:\n        df (pd.DataFrame): The merged dataset.\n        file_path (str): Path to save the dataset.\n    \"\"\"\n    try:\n        df.to_csv(file_path, index=False)\n        print(f\"Merged dataset saved successfully as '{file_path}'.\")\n    except Exception as e:\n        print(f\"Error saving dataset: {e}\")\n\ndef print_dataset_info(df):\n    \"\"\"\n    Prints the dataset's column names, first 10 rows, and total number of rows and columns.\n\n    Args:\n        df (pd.DataFrame): The dataset to print.\n    \"\"\"\n    num_rows, num_columns = df.shape\n    print(f\"\\nTotal Rows: {num_rows}, Total Columns: {num_columns}\")\n\n    print(\"\\nAll Columns in Merged Dataset:\")\n    print(list(df.columns))\n\n    print(\"\\nFirst 10 Rows of Merged Dataset:\")\n    print(df.head(10))\n\ndef main():\n    \"\"\"\n    Main function to load, merge, save, and print dataset information.\n    \"\"\"\n    cleaned_df = load_dataset(CLEANED_FINAL_FILE_PATH)\n    birds_df = load_dataset(BIRDS_FILE_PATH)\n\n    if cleaned_df is not None and birds_df is not None:\n        merged_df = merge_datasets(cleaned_df, birds_df)\n        if merged_df is not None:\n            save_merged_dataset(merged_df, MERGED_FILE_PATH)\n            print_dataset_info(merged_df)  # Print dataset details\n\nif __name__ == \"__main__\":\n    main()\n",
  "history_output" : "Dataset loaded successfully from /media/volume1/cleaned_final_merged_dataset.csv\nDataset loaded successfully from /media/volume1/hpai-wild-birds-2022.csv\nDatasets merged successfully.\nMerged dataset saved successfully as '/media/volume1/final_merged_with_birds.csv'.\nTotal Rows: 22242, Total Columns: 35\nAll Columns in Merged Dataset:\n['County', 'Year', 'Days with AQI', 'Good Days', 'Moderate Days', 'Unhealthy for Sensitive Groups Days', 'Unhealthy Days', 'Very Unhealthy Days', 'Hazardous Days', 'Max AQI', '90th Percentile AQI', 'Median AQI', 'Days CO', 'Days NO2', 'Days Ozone', 'Days PM2.5', 'Days PM10', '2023 Rural-Urban Continuum Codes([rural urban note])', 'Age-Adjusted Incidence Rate([rate note]) - cases per 100,000', 'Lower 95% Confidence Interval', 'Upper 95% Confidence Interval', 'Average Annual Count', 'Recent Trend', 'Recent 5-Year Trend ([trend note]) in Incidence Rates', 'Lower 95% Confidence Interval.1', 'Upper 95% Confidence Interval.1', 'Region', 'Zone', 'Collection Date', 'Date Detected', 'HPAI Strain', 'Bird Species', 'WOAH Classification', 'Sampling Method', 'Submitting Agency']\nFirst 10 Rows of Merged Dataset:\n    County  Year  ...      Sampling Method             Submitting Agency\n0  Baldwin  2017  ...                  NaN                           NaN\n1     Clay  2017  ...  Morbidity/Mortality  MO Dept of Conservation/USGS\n2     Clay  2017  ...  Morbidity/Mortality                  KS DWP/SCWDS\n3     Clay  2017  ...  Morbidity/Mortality                       FL FWCC\n4     Clay  2017  ...  Morbidity/Mortality                       FL FWCC\n5     Clay  2017  ...  Morbidity/Mortality                       FL FWCC\n6     Clay  2017  ...  Morbidity/Mortality                       FL FWCC\n7     Clay  2017  ...  Morbidity/Mortality                          NWDP\n8     Clay  2017  ...       Hunter Harvest                          NWDP\n9     Clay  2017  ...       Hunter Harvest                          NWDP\n[10 rows x 35 columns]\n",
  "history_begin_time" : 1742474873597,
  "history_end_time" : 1742474874433,
  "history_notes" : null,
  "history_process" : "4h36mr",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bhllcjcu2bl",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1742475919602,
  "history_notes" : null,
  "history_process" : "4h36mr",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]